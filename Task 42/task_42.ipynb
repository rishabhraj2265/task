{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "WjyAmimNRsdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wjuu1JpFQh1n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD DATA**"
      ],
      "metadata": {
        "id": "-CyDr20TRpIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Occupancy.csv\")\n",
        "df['date'] = pd.to_datetime(df['date'])"
      ],
      "metadata": {
        "id": "etxhgraGRGa8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BATCH PROCESSING**"
      ],
      "metadata": {
        "id": "DvUoGSplRlGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== BATCH PROCESSING ===\")\n",
        "\n",
        "X = df[['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']]\n",
        "y = df['Occupancy']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "batch_model = LogisticRegression(max_iter=1000)\n",
        "batch_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = batch_model.predict(X_test)\n",
        "\n",
        "batch_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"Precision\": precision_score(y_test, y_pred),\n",
        "    \"Recall\": recall_score(y_test, y_pred),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred)\n",
        "}\n",
        "\n",
        "print(\"Batch Metrics:\")\n",
        "for k, v in batch_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ6BUodsRJ7N",
        "outputId": "fd20d5b6-b58f-4936-ee5e-4db797c71dc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BATCH PROCESSING ===\n",
            "Batch Metrics:\n",
            "Accuracy: 0.9917\n",
            "Precision: 0.9683\n",
            "Recall: 0.9957\n",
            "F1-Score: 0.9818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STREAM PROCESSING SIMULATION**"
      ],
      "metadata": {
        "id": "w2KY0a-QRefo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== STREAM PROCESSING ===\")\n",
        "stream_alerts = []\n",
        "start_time = time.time()\n",
        "\n",
        "def stream_processing(df):\n",
        "    predictions = []\n",
        "    for _, row in df.iterrows():\n",
        "\n",
        "        input_features = pd.DataFrame([{\n",
        "            'Temperature': row['Temperature'],\n",
        "            'Humidity': row['Humidity'],\n",
        "            'Light': row['Light'],\n",
        "            'CO2': row['CO2'],\n",
        "            'HumidityRatio': row['HumidityRatio']\n",
        "                                          }])\n",
        "        prediction = batch_model.predict(input_features)[0]\n",
        "\n",
        "        predictions.append(prediction)\n",
        "\n",
        "        if row['CO2'] > 800 and prediction == 1:\n",
        "            stream_alerts.append((row['date'], row['CO2']))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "stream_preds = stream_processing(X_test.assign(date=df.loc[X_test.index, 'date']))\n",
        "\n",
        "stream_metrics = {\n",
        "    \"Accuracy\": accuracy_score(y_test, stream_preds),\n",
        "    \"Precision\": precision_score(y_test, stream_preds),\n",
        "    \"Recall\": recall_score(y_test, stream_preds),\n",
        "    \"F1-Score\": f1_score(y_test, stream_preds)\n",
        "}\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Stream Metrics (simulated, using same model):\")\n",
        "for k, v in stream_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "print(f\"\\nStream Alerts Raised: {len(stream_alerts)}\")\n",
        "print(f\"Stream Processing Time: {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-8ugGU8RNXT",
        "outputId": "7f999222-027f-49b0-8754-7ecfbe0b3d17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== STREAM PROCESSING ===\n",
            "Stream Metrics (simulated, using same model):\n",
            "Accuracy: 0.9917\n",
            "Precision: 0.9683\n",
            "Recall: 0.9957\n",
            "F1-Score: 0.9818\n",
            "\n",
            "Stream Alerts Raised: 645\n",
            "Stream Processing Time: 5.25 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMPARISON TABLE**"
      ],
      "metadata": {
        "id": "L9n9R_kfRcbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== COMPARISON ===\")\n",
        "import pandas as pd\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    \"Metric\": list(batch_metrics.keys()),\n",
        "    \"Batch Processing\": list(batch_metrics.values()),\n",
        "    \"Stream Processing (Simulated)\": list(stream_metrics.values())\n",
        "})\n",
        "\n",
        "print(comparison_df.to_string(index=False))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUjzSgmRRS3d",
        "outputId": "98fde833-118f-4d59-c780-911e640fc011"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== COMPARISON ===\n",
            "   Metric  Batch Processing  Stream Processing (Simulated)\n",
            " Accuracy          0.991732                       0.991732\n",
            "Precision          0.968288                       0.968288\n",
            "   Recall          0.995652                       0.995652\n",
            " F1-Score          0.981779                       0.981779\n"
          ]
        }
      ]
    }
  ]
}